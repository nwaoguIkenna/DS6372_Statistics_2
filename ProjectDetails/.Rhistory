MeanSensVersi = mean(stat$c.sensVersicolor.)
MeanSensVirg = mean(stat$c.sensVirginica.)
MeanAcc
MeanspecSetosa
MeanspecVersi
MeanspecVirg
MeanSensSetosa
MeanSensVersi
MeanSensVirg
library(caret)
iterations = 100
stat = data.frame()
splitPerc = .7 #Training / Test split Percentage
for(j in 1:iterations)
{
trainIndices = sample(1:dim(iris)[1],round(splitPerc * dim(iris)[1]))
train = iris[trainIndices,]
test = iris[-trainIndices,]
classifications = knn(train[,c(1,3)],test[,c(1,3)],train$Species, prob = TRUE, k = 5)
table(classifications,test$Species)
CM = confusionMatrix(table(classifications,test$Species))
acc = CM$overall[1]
specSetosa = CM$byClass[1,2]
specVersicolor = CM$byClass[2,2]
specVirginica = CM$byClass[3,2]
sensSetosa = CM$byClass[1,1]
sensVersicolor = CM$byClass[2,1]
sensVirginica = CM$byClass[3,1]
stat <- bind_rows(stat,data.frame(c(acc),c(specSetosa),c(specVersicolor),c(specVirginica),c(sensSetosa),c(sensVersicolor),c(sensVirginica)))
}
stat <- tibble::rowid_to_column(stat, "Seed")
MeanAcc = mean(stat$c.acc.)
MeanspecSetosa = mean(stat$c.specSetosa.)
MeanspecVersi = mean(stat$c.specVersicolor.)
MeanspecVirg = mean(stat$c.specVirginica.)
MeanSensSetosa = mean(stat$c.sensSetosa.)
MeanSensVersi = mean(stat$c.sensVersicolor.)
MeanSensVirg = mean(stat$c.sensVirginica.)
MeanAcc
MeanspecSetosa
MeanspecVersi
MeanspecVirg
MeanSensSetosa
MeanSensVersi
MeanSensVirg
knitr::opts_chunk$set(echo = FALSE)
summary(cars)
plot(pressure)
knitr::opts_chunk$set(echo = FALSE)
1.  How many breweries are present in each state?
brews <- read.csv(file.choose(),header = TRUE)
brews
brew
brew <- read.csv(file.choose(),header = TRUE)
brew
install.packages(c("RCurl", "WDI", "XML"))
brewState <-table(brew$State)
brewState
library(nycflights13)
library(dplyr)
library(plotly)       # plotly is dependent on dplyr
library(tidyverse)
library(tidyr)
library(plyr)
#library(qnorm)
library(ggplot2)
library(GGally)
#For String
library(stringr)
library(maps)
library(mapproj)
library(jsonlite) #for parsing json
library(tm)
brew %>% group_by(state)%>% summarize(count = count(state))
brew %>% group_by(State)%>% summarize(count = count(State))
brew
brewState <- brew %>% group_by(State)%>% summarize(count = count(State))
#Import Beers data
beers <- read.csv(file.choose(),header = TRUE)
beers
mergeData = inner_join(brew,beers, by = c("Brew_ID" = "Brewery_id"))
mergeData
names(mergeData)
mergeData <- rename(mergeData$Name.x = brewName)
mergeData <- rename(mergeData, Name.x = brewName)
mergeData <- rename(mergeData, Name.x = brewName)
mergeData <- rename(mergeData, brewName = Name.x)
#Observe that ID on beers - Brewery_id and and breweries - Brew_ID  - we rename by Brew_ID
brew <- rename(brew, brewName = Name)
# For KNN
library(class)
library(caret)
library(e1071)
library(multcomp)
library(pairwiseCI)
library(nycflights13)
library(dplyr)
library(plotly)       # plotly is dependent on dplyr
library(tidyverse)
library(tidyr)
library(plyr)
#library(qnorm)
library(ggplot2)
library(GGally)
mergeData <- rename(mergeData, brewName = Name.x)
#Observe that ID on beers - Brewery_id and and breweries - Brew_ID  - we rename by Brew_ID
brew <- rename(brew, brewName = Name)
beers <- rename(beers, Name_Beer = Name)
beers
brew
#Observe that ID on beers - Brewery_id and and breweries - Brew_ID  - we rename by Brew_ID
brew <- rename(brew, brewName = Name)
#Observe that ID on beers - Brewery_id and and breweries - Brew_ID  - we rename by Brew_ID
brew <- rename(brew, 'brewName' = 'Name')
library(plyr)
library(dplyr)
knitr::opts_chunk$set(echo = FALSE)
brew.state
brews <- read.csv(file.choose(),header = TRUE)
brew.state <-table(breweries$State)
brews <- read.csv(file.choose(),header = TRUE)
brew.state <-table(brews$State)
brew.state
#Import Beers data
beers <- read.csv(file.choose(),header = TRUE)
beers
#Observe that ID on beers - Brewery_id and and breweries - Brew_ID  - we rename by Brew_ID
beers <- rename(beers, Brew_ID = Brewery_id)
mergeData <- dplyr::rename(mergeData, brewName = Name.x)
mergeData <- dplyr::rename(mergeData, beerName = Name.y)
names(mergeData)
brew.beer %>% summarise_all(funs(sum(is.na(.))))
brew.beer %>% summarise_all(funs(sum(is.na(.))))
mergeData %>% summarise_all(funs(sum(is.na(.))))
mergeData %>% summarise_all(list(sum(is.na(.))))
colSums(is.na(mergeData))
library(nycflights13)
library(dplyr)
library(plotly)       # plotly is dependent on dplyr
library(tidyverse)
library(tidyr)
library(plyr)
#library(qnorm)
library(ggplot2)
library(GGally)
#For String
library(stringr)
library(maps)
library(mapproj)
library(jsonlite) #for parsing json
library(tm)
# For KNN
library(class)
library(caret)
library(e1071)
library(multcomp)
library(pairwiseCI)
library(SLOPE)
library(urltools)
library(RCurl)
#install.packages('mice')
library(mice)
install.packages('mice')
library(mice)
cars
cars <- read.csv(file.choose(),header = TRUE)
cars%>%summarise_all(funs(sum(is.na(.))))
imputeHP <- mice(cars,m=5,maxit=50,meth='pmm',seed=50)
install.packages('mice')
install.packages("mice")
install.packages("mice")
library(mice)
library(nycflights13)
library(dplyr)
library(plotly)       # plotly is dependent on dplyr
library(tidyverse)
library(tidyr)
library(plyr)
#library(qnorm)
library(ggplot2)
library(GGally)
#For String
library(stringr)
library(maps)
library(mapproj)
library(jsonlite) #for parsing json
library(tm)
# For KNN
library(class)
library(caret)
library(e1071)
library(multcomp)
library(pairwiseCI)
library(SLOPE)
library(urltools)
library(RCurl)
install.packages('mice')
library(mice)
install.packages("mice")
install.packages('mitml')
knitr::opts_chunk$set(echo = TRUE)
shinyApp(ui, server)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
library(shiny)
ui <- fluidPage(
# App title ----
titlePanel("Hello Shiny!"),
# Sidebar layout with input and output definitions ----
sidebarLayout(
# Sidebar panel for inputs ----
sidebarPanel(
# Input: Slider for the number of bins ----
sliderInput(inputId = "bins",
label = "Number of bins:",
min = 1,
max = 50,
value = 30)
),
# Main panel for displaying outputs ----
mainPanel(
# Output: Histogram ----
plotOutput(outputId = "distPlot")
)
)
)
# Define server logic required to draw a histogram ----
server <- function(input, output) {
# Histogram of the Old Faithful Geyser Data ----
# with requested number of bins
# This expression that generates a histogram is wrapped in a call
# to renderPlot to indicate that:
#
# 1. It is "reactive" and therefore should be automatically
#    re-executed when inputs (input$bins) change
# 2. Its output type is a plot
output$distPlot <- renderPlot({
x    <- faithful$waiting
bins <- seq(min(x), max(x), length.out = input$bins + 1)
hist(x, breaks = bins, col = "#75AADB", border = "white",
xlab = "Waiting time to next eruption (in mins)",
main = "Histogram of waiting times")
})
}
shinyApp(ui, server)
shinyApp(ui, server)
library(shiny)
ui <- fluidPage(
# App title ----
titlePanel("Hello Shiny!"),
# Sidebar layout with input and output definitions ----
sidebarLayout(
# Sidebar panel for inputs ----
sidebarPanel(
# Input: Slider for the number of bins ----
sliderInput(inputId = "bins",
label = "Number of bins:",
min = 1,
max = 50,
value = 30)
),
# Main panel for displaying outputs ----
mainPanel(
# Output: Histogram ----
plotOutput(outputId = "distPlot")
)
)
)
# Define server logic required to draw a histogram ----
server <- function(input, output) {
# Histogram of the Old Faithful Geyser Data ----
# with requested number of bins
# This expression that generates a histogram is wrapped in a call
# to renderPlot to indicate that:
#
# 1. It is "reactive" and therefore should be automatically
#    re-executed when inputs (input$bins) change
# 2. Its output type is a plot
output$distPlot <- renderPlot({
x    <- faithful$waiting
bins <- seq(min(x), max(x), length.out = input$bins + 1)
hist(x, breaks = bins, col = "#75AADB", border = "white",
xlab = "Waiting time to next eruption (in mins)",
main = "Histogram of waiting times")
})
}
shinyApp(ui, server)
rsconnect::setAccountInfo(name='inwaogu',
token='8FECA6732371C9B7606AF1EC93BE78F3',
secret='Udt0HD14Xj+gAVHUOd2NxNNxGa4c0TPk4yBl4I1q')
library(rsconnect)
rsconnect::deployApp('~/datascience/DS6306/html/build/Beer.Rmd')
ACT<-read.csv("~/datascience/DS6372/Unit3/Unit3PreLive/MathACT.csv")
attach(ACT)
mysummary<-function(x){
result<-c(length(x),mean(x),sd(x),sd(x)/length(x),min(x),max(x),IQR(x))
names(result)<-c("N","Mean","SD","SE",'Min','Max','IQR')
return(result)
}
sumstats<-aggregate(Score~Background*Sex,data=ACT,mysummary)
sumstats<-cbind(sumstats[,1:2],sumstats[,-(1:2)])
ggplot(sumstats,aes(x=Background,y=Mean,group=Sex,colour=Sex))+
ylab("ACT Score")+
geom_line()+
geom_point()+
geom_errorbar(aes(ymin=Mean-SD,ymax=Mean+SD),width=.1)
library(ggplot2)
ggplot(sumstats,aes(x=Background,y=Mean,group=Sex,colour=Sex))+
ylab("ACT Score")+
geom_line()+
geom_point()+
geom_errorbar(aes(ymin=Mean-SD,ymax=Mean+SD),width=.1)
ggplot(sumstats,aes(x=Background,y=Mean,group=Sex,colour=Sex))+
ylab("ACT Score")+
geom_line()+
geom_point()+
geom_errorbar(aes(ymin=Mean-SE,ymax=Mean+SE),width=.1)
ggplot(sumstats,aes(x=Background,y=Mean,group=Sex,colour=Sex))+
ylab("ACT Score")+
geom_line()+
geom_point()+
geom_errorbar(aes(ymin=Mean-SE,ymax=Mean+SE),width=.1)
model.fit<-aov(Score~Background+Sex+Background:Sex,data=ACT)
myfits<-data.frame(fitted.values=model.fit$fitted.values,residuals=model.fit$residuals)
Anova(model.fit,type=3)
library(car)
Anova(model.fit,type=3)
TukeyHSD(model.fit,"Background",conf.level=.95)
TukeyHSD(model.fit,"Background:Sex",conf.level=.95)
TukeyHSD(model.fit,"Background:Sex",conf.level=.99)
TukeyHSD(model.fit,"Background:Sex",conf.level=.99)
TukeyHSD(model.fit,"Background:Sex",conf.level=.10)
TukeyHSD(model.fit,"Background:Sex")
plot(TukeyHSD(model.fit,"Background:Sex",conf.level=.95))
plot(TukeyHSD(model.fit,"Background:Sex",conf.level=.99))
plot(TukeyHSD(model.fit,"Background:Sex",conf.level=.99))
plot(TukeyHSD(model.fit,"Background:Sex",conf.level=.95))
plot(TukeyHSD(model.fit,"Background:Sex",conf.level=.95))
plot(TukeyHSD(model.fit,"Background:Sex",conf.level=.99))
library(Sleuth3)
head(ex1317)
ex1317
ACT
mysummary<-function(x){
result<-c(length(x),mean(x),sd(x),sd(x)/length(x),min(x),max(x),IQR(x))
names(result)<-c("N","Mean","SD","SE",'Min','Max','IQR')
return(result)
}
sumstats<-aggregate(Iridium~DepthCat*Strata,data=ex1317,mysummary)
sumstats<-cbind(sumstats[,1:2],sumstats[,-(1:2)])
sumstats
ex1317
ggplot(sumstats,aes(x=DepthCat,y=Mean,group=Strata,colour=Strata))+
ylab("Iridium")+
geom_line()+
geom_point()+
geom_errorbar(aes(ymin=Mean-SE,ymax=Mean+SE),width=.1)
mysummary<-function(x){
result<-c(length(x),mean(x),sd(x),sd(x)/length(x),min(x),max(x),IQR(x))
names(result)<-c("N","Mean","SD","SE",'Min','Max','IQR')
return(result)
}
sumstats<-aggregate(Score~Background*Sex,data=ACT,mysummary)
sumstats<-cbind(sumstats[,1:2],sumstats[,-(1:2)])
sumstats
mysummary<-function(x){
result<-c(length(x),mean(x),sd(x),sd(x)/length(x),min(x),max(x),IQR(x))
names(result)<-c("N","Mean","SD","SE",'Min','Max','IQR')
return(result)
}
sumstats<-aggregate(Iridium~DepthCat*Strata,data=ex1317,mysummary)
sumstats<-cbind(sumstats[,1:2],sumstats[,-(1:2)])
sumstats
ggplot(sumstats,aes(x=DepthCat,y=Mean,group=Strata,colour=Strata))+
ylab("Iridium")+
geom_line()+
geom_point()+
geom_errorbar(aes(ymin=Mean-SE,ymax=Mean+SE),width=.1)
model.fit<-aov(Iridium~DepthCat+Strata+DepthCat:Strata,data=ex1317)
par(mfrow=c(1,2))
plot(model.fit$fitted.values,model.fit$residuals,ylab="Resdiduals",xlab="Fitted")
qqnorm(model.fit$residuals)
library(gridExtra)
myfits<-data.frame(fitted.values=model.fit$fitted.values,residuals=model.fit$residuals)
#Residual vs Fitted
plot1<-ggplot(myfits,aes(x=fitted.values,y=residuals))+ylab("Residuals")+
xlab("Predicted")+geom_point()
#QQ plot of residuals  #Note the diagonal abline is only good for qqplots of normal data.
plot2<-ggplot(myfits,aes(sample=residuals))+
stat_qq()+geom_abline(intercept=mean(myfits$residuals), slope = sd(myfits$residuals))
#Histogram of residuals
plot3<-ggplot(myfits, aes(x=residuals)) +
geom_histogram(aes(y=..density..),binwidth=1,color="black", fill="gray")+
geom_density(alpha=.1, fill="red")
grid.arrange(plot1, plot2,plot3, ncol=3)
plot3<-ggplot(myfits, aes(x=residuals)) +
geom_histogram(aes(y=..density..),binwidth=1,color="black", fill="gray")
grid.arrange(plot1, plot2,plot3, ncol=3)
plot3<-ggplot(myfits, aes(x=residuals)) +
geom_histogram(aes(y=..density..),binwidth=1,color="black", fill="gray")+
geom_density(alpha=.8, fill="red")
grid.arrange(plot1, plot2,plot3, ncol=3)
Anova(model.fit,type=3)
model.fit<-aov(Iridium~DepthCat+Strata,data=ex1317)
par(mfrow=c(1,2))
plot(model.fit$fitted.values,model.fit$residuals,ylab="Resdiduals",xlab="Fitted")
qqnorm(model.fit$residuals)
library(gridExtra)
myfits<-data.frame(fitted.values=model.fit$fitted.values,residuals=model.fit$residuals)
#Residual vs Fitted
plot1<-ggplot(myfits,aes(x=fitted.values,y=residuals))+ylab("Residuals")+
xlab("Predicted")+geom_point()
#QQ plot of residuals  #Note the diagonal abline is only good for qqplots of normal data.
plot2<-ggplot(myfits,aes(sample=residuals))+
stat_qq()+geom_abline(intercept=mean(myfits$residuals), slope = sd(myfits$residuals))
#Histogram of residuals
plot3<-ggplot(myfits, aes(x=residuals)) +
geom_histogram(aes(y=..density..),binwidth=1,color="black", fill="gray")+
geom_density(alpha=.8, fill="red")
grid.arrange(plot1, plot2,plot3, ncol=3)
Anova(model.fit,type=3)
TukeyHSD(model.fit,"DepthCat",conf.level=.95)
TukeyHSD(model.fit,"Strata",conf.level=.95)
TukeyHSD(model.fit,"DepthCat:Strata",conf.level=.95)
sumstats<-aggregate(Iridium~DepthCat*Strata,data=ex1317,mysummary)
sumstats<-cbind(sumstats[,1:2],sumstats[,-(1:2)])
sumstats
model.fit
sumstats<-aggregate(Iridium~DepthCat*StrataDepthCat:Strata,data=ex1317,mysummary)
mysummary<-function(x){
result<-c(length(x),mean(x),sd(x),sd(x)/length(x),min(x),max(x),IQR(x))
names(result)<-c("N","Mean","SD","SE",'Min','Max','IQR')
return(result)
}
sumstats<-aggregate(Iridium~DepthCat*Strata,DepthCat:Strata,data=ex1317,mysummary)
model.fit<-aov(Iridium~DepthCat+Strata+DepthCat:Strata,data=ex1317)
Anova(model.fit,type=3)
TukeyHSD(model.fit,"DepthCat:Strata",conf.level=.95)
ggplot(sumstats,aes(x=DepthCat,y=Mean,group=Strata,colour=Strata))+
ylab("Iridium")+
geom_line()+
geom_point()+
geom_errorbar(aes(ymin=Mean-SE,ymax=Mean+SE),width=.1)
ggplot(sumstats,aes(x=DepthCat,y=Mean,group=Strata,colour=Strata))+
ylab("Iridium")+
geom_line()+
geom_point()+
geom_errorbar(aes(ymin=Mean-SD,ymax=Mean+SD),width=.1)
TukeyHSD(model.fit,"Background:Sex",conf.level=.95)
model.fit<-aov(Score~Background+Sex+Background:Sex,data=ACT)
TukeyHSD(model.fit,"Background:Sex",conf.level=.95)
plot(TukeyHSD(model.fit,"Background:Sex",conf.level=.95))
model.fit<-aov(Iridium~DepthCat+Strata+DepthCat:Strata,data=ex1317)
contrast.factor<-~DepthCat*Strata
mycontrast<-c("amale-afemale","bmale-bfemale","cmale-cfemale",'','s','d')
dat<-ex1317
final.result<-c()
for( j in 1:length(mycontrast)){
contrast.factor.names<-gsub(" ", "", unlist(strsplit(as.character(contrast.factor),split = "*", fixed = T))[-1])
contrast.factor.2 <- vector("list", length(contrast.factor.names))
for (i in 1:length(contrast.factor.names)) {
contrast.factor.2[[i]] <- levels(dat[, contrast.factor.names[i]])
}
new.factor.levels <- do.call(paste, c(do.call(expand.grid,
contrast.factor.2), sep = ""))
temp.cont<-mycontrast[j]
contrast2 <- list(comparison = as.vector(do.call(makeContrasts,
list(contrasts = temp.cont, levels = new.factor.levels))))
contrast.result <- summary(contrast(lsmeans(model.fit,
contrast.factor), contrast2, by = NULL))
final.result<-rbind(final.result,contrast.result)
}
library(limma)
library(lsmeans) #maybe need eemeans package
library(limma)
install.packages('limma')
mela<-read.csv("~/datascience/DS6372/Unit4/Unit4PreLive/Melanomatimeseries.csv")
mela
ggplot(mela,aes(x=Year,y=Sunspot))+ylab("Residuals")+
xlab("Predicted")+geom_point()
reviews
library(dplyr)
library(plotly)
library(leaps)
library(MASS)
library(caret)
library(olsrr)
library(car)
setwd("~/datascience/DS6372/ProjectDetails")
reviews<-read.csv("beer_reviews.csv")
names(reviews)
regData <- reviews %>% filter(!is.na(beer_abv)) %>% group_by(brewery_name,beer_name) %>% summarise(all = mean(review_overall),aroma = mean(review_aroma), appearance = mean(review_appearance), palate = mean(review_palate),abv = mean(beer_abv), taste = mean(review_taste),count = n())
names(regData)
full.model <- lm(all ~ aroma + appearance + palate + abv + taste  + abv*taste + abv*palate + palate* taste,data=regData)
## All possible regression model and the values they provide.
all <- ols_step_all_possible(full.model)
View(all)
View(all)
plot(all) #This displays all the attributes of the all data into a plot showing which ones are the better values.
plot(all) #This displays all the attributes of the all data into a plot showing which ones are the better values.
plot(all) #This displays all the attributes of the all data into a plot showing which ones are the better values.
## All possible regression model and the values they provide.
all <- ols_step_all_possible(full.model)
View(all)
# Best suset of regression model
subset <- ols_step_best_subset(full.model)
view(subset)   # This shows all the best model based on the values of a given parameter
View(subset)   # This shows all the best model based on the values of a given parameter
plot(subset)  # This displays all the parameters on a plot
View(subset)   # This shows all the best model based on the values of a given parameter
summary(subset)# This shows all the best model based on the values of a given parameter
subset
